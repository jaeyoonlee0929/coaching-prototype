import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import openai
import re

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="Executive Leadership Coach",
    page_icon="ğŸ‘‘",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- API Key ì„¤ì • ---
try:
    OPENAI_API_KEY = st.secrets["JYL"]
except (FileNotFoundError, KeyError):
    OPENAI_API_KEY = None

# --- ì—­ëŸ‰ ê·¸ë£¹ ì •ì˜ ---
COMPETENCY_GROUPS = {
    "SKMSì— ëŒ€í•œ í™•ì‹ ê³¼ ì—´ì •": ["SKMSì— ëŒ€í•œ í™•ì‹ ", "êµ¬ì„±ì›/ì´í•´ê´€ê³„ì í–‰ë³µ ì¶”êµ¬", "íŒ¨ê¸°/ì†”ì„ ìˆ˜ë²”", "Integrity"],
    "í˜ì‹ ì  ì „ëµ ìˆ˜ë¦½": ["ì „ëµì  Insight", "ë‹´ë‹¹ ì¡°ì§ ë³€í™” Design", "ë¹„ì „ ê³µìœ /ì§€ì†ì  ë³€í™” ì¶”ì§„"],
    "ê³¼ê°í•œ ëŒíŒŒì™€ ì‹¤í–‰": ["SUPEX ëª©í‘œ ì„¤ì •", "ë‚´Â·ì™¸ë¶€ í­ë„“ì€ í˜‘ì—…", "ì‹ ì†í•œ ì‹¤í–‰ ë° ì„±ê³¼ ì°½ì¶œ"],
    "VWBE ë¬¸í™”êµ¬ì¶•": ["êµ¬ì„±ì› VWBEí™˜ê²½ ì¡°ì„± í™œë™ ì§€ì›", "ì‹ ë¢° ê¸°ë°˜ì˜ í˜‘ë ¥ ì´‰ì§„", "íŒ¨ê¸° ì¸ì¬ ì¸ì •/ìœ¡ì„±"]
}

# --- ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ---
@st.cache_data
def load_data(file):
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        return df
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def normalize_text(text):
    return re.sub(r'[\s\Â·\.\,\-\_]', '', str(text)).lower()

def parse_columns(df):
    """
    ì»¬ëŸ¼ëª…ì„ ë¶„ì„í•˜ì—¬ ì ìˆ˜(Numeric)ì™€ ì£¼ê´€ì‹(Text)ì„ êµ¬ë¶„í•˜ê³ ,
    ëŒ€ìƒ(êµ¬ì„±ì›/ë™ë£Œ)ê³¼ ì—°ë„ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    """
    member_scores = {} 
    peer_scores = {}   
    member_texts = {}  # êµ¬ì„±ì› ì£¼ê´€ì‹
    peer_texts = {}    # ë™ë£Œ ì£¼ê´€ì‹
    meta_cols = []
    
    peer_pattern = re.compile(r"^(.*)_ë™ë£Œ_(\d{2}ë…„)$")
    member_pattern = re.compile(r"^(.*)_(\d{2}ë…„)$")
    
    for col in df.columns:
        # 1. ë™ë£Œ ë°ì´í„° í™•ì¸
        peer_match = peer_pattern.match(col)
        if peer_match:
            year = peer_match.group(2)
            if pd.api.types.is_numeric_dtype(df[col]):
                if year not in peer_scores: peer_scores[year] = []
                peer_scores[year].append(col)
            else:
                if year not in peer_texts: peer_texts[year] = []
                peer_texts[year].append(col)
            continue
            
        # 2. êµ¬ì„±ì› ë°ì´í„° í™•ì¸
        member_match = member_pattern.match(col)
        if member_match:
            year = member_match.group(2)
            if pd.api.types.is_numeric_dtype(df[col]):
                if year not in member_scores: member_scores[year] = []
                member_scores[year].append(col)
            else:
                if year not in member_texts: member_texts[year] = []
                member_texts[year].append(col)
        else:
            meta_cols.append(col)
            
    return meta_cols, member_scores, peer_scores, member_texts, peer_texts

def custom_metric(label, value, delta=None, delta_color="normal", show_arrow=False):
    """HTML ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­"""
    delta_html = ""
    if delta:
        try:
            match = re.search(r"([+-]?\d+\.?\d*)", str(delta))
            if match:
                delta_val = float(match.group(1))
                text_color = "#666"
                arrow_char = ""
                
                if delta_val > 0:
                    if delta_color == "normal": text_color = "#09ab3b"
                    elif delta_color == "inverse": text_color = "#ff2b2b"
                    arrow_char = "â†‘" if show_arrow else ""
                elif delta_val < 0:
                    if delta_color == "normal": text_color = "#ff2b2b"
                    elif delta_color == "inverse": text_color = "#09ab3b"
                    arrow_char = "â†“" if show_arrow else ""
                
                delta_str = f"{arrow_char} {delta}" if show_arrow else f"{delta}"
                delta_html = f'<span style="color: {text_color}; font-size: 1rem; margin-left: 8px; font-weight: 600;">{delta_str}</span>'
        except:
            delta_html = f'<span style="color: #666; font-size: 1rem; margin-left: 8px;">{delta}</span>'

    html_code = f"""
    <div style="display: flex; flex-direction: column; margin-bottom: 1.5rem;">
        <span style="font-size: 1rem; font-weight: 500; margin-bottom: 4px; opacity: 0.8;">{label}</span>
        <div style="display: flex; align-items: baseline;">
            <span style="font-size: 2.2rem; font-weight: 700;">{value}</span>
            {delta_html}
        </div>
    </div>
    """
    st.markdown(html_code, unsafe_allow_html=True)

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.title("ğŸ‘‘ ì„ì› ë¦¬ë”ì‹­ ì½”ì¹­")
    st.info("ë¦¬ë”ì‹­ ì§„ë‹¨ ê²°ê³¼(Excel)ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "csv"])
    
    selected_leader = None
    df = None
    
    if uploaded_file:
        df = load_data(uploaded_file)
        if df is not None:
            name_col = next((c for c in df.columns if "ì´ë¦„" in c or "Name" in c), df.columns[1])
            leader_list = df[name_col].unique().tolist()
            selected_leader_name = st.selectbox("ëŒ€ìƒ ì„ì› ì„ íƒ", leader_list)
            leader_data = df[df[name_col] == selected_leader_name].iloc[0]
            
            if not OPENAI_API_KEY:
                st.warning("âš ï¸ API Key ë¯¸ì„¤ì • (AI ê¸°ëŠ¥ ì œí•œ)")

# --- ë©”ì¸ ë¡œì§ ---
if df is not None and selected_leader_name:
    # 1. ì»¬ëŸ¼ íŒŒì‹±
    meta_cols, member_map, peer_map, member_text_map, peer_text_map = parse_columns(df)
    sorted_years = sorted(member_map.keys())
    latest_year = sorted_years[-1]
    
    # 2. ì—­ëŸ‰ ë§¤í•‘ & ì ìˆ˜ ì¶”ì¶œ
    raw_competencies = [col.replace(f"_{latest_year}", "") for col in member_map[latest_year]]
    norm_comp_map = {normalize_text(c): c for c in raw_competencies}
    
    grouped_scores = {}
    detailed_scores = {} 

    for year in sorted_years:
        year_group_data = {}
        year_detail_data = {}
        
        for col in member_map[year]:
            if "_ë™ë£Œ_" in col: continue
            comp_name = col.replace(f"_{year}", "")
            val = leader_data[col]
            if pd.notna(val) and val > 0:
                year_detail_data[comp_name] = val
            else:
                year_detail_data[comp_name] = 0
        detailed_scores[year] = year_detail_data
        
        for group_name, sub_items in COMPETENCY_GROUPS.items():
            scores = []
            for item in sub_items:
                norm_item = normalize_text(item)
                target_col = None
                if item in year_detail_data: target_col = item
                elif norm_item in norm_comp_map and norm_comp_map[norm_item] in year_detail_data:
                    target_col = norm_comp_map[norm_item]
                
                if target_col:
                    val = year_detail_data[target_col]
                    if val > 0: scores.append(val)
            
            if scores: year_group_data[group_name] = sum(scores) / len(scores)
            else: year_group_data[group_name] = 0.0
        
        grouped_scores[year] = year_group_data

    # Common Stats
    avg_scores = {}
    for y in sorted_years:
        vals = [v for v in detailed_scores[y].values() if v > 0]
        avg_scores[y] = sum(vals) / len(vals) if vals else 0

    curr_score = avg_scores[latest_year]
    prev_year = sorted_years[-2] if len(sorted_years) > 1 else None
    delta_total = (curr_score - avg_scores[prev_year]) if prev_year else 0
    
    latest_series = pd.Series(detailed_scores[latest_year])
    latest_series = latest_series[latest_series > 0]
    
    if not latest_series.empty:
        top_comp = latest_series.idxmax()
        bot_comp = latest_series.idxmin()
    else:
        top_comp, bot_comp = "-", "-"

    def get_delta_str(comp_name):
        if not prev_year: return None
        prev = detailed_scores[prev_year].get(comp_name, 0)
        curr = detailed_scores[latest_year].get(comp_name, 0)
        if prev > 0 and curr > 0:
            return f"{curr - prev:+.1f}"
        return None

    # --- UI ---
    st.title(f"ğŸ“Š {selected_leader_name} ë‹˜ ë¦¬ë”ì‹­ ì§„ë‹¨ ë¶„ì„ (3ê°œë…„)")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ì¢…í•© ëŒ€ì‹œë³´ë“œ", "ğŸ“ ì£¼ê´€ì‹ ì‹¬ì¸µë¶„ì„", "ğŸ¤– AI ì½”ì¹­"])
    
    # [TAB 1] Overview
    with tab1:
        st.subheader("Overview (êµ¬ì„±ì› ì‘ë‹µ ê¸°ì¤€)")
        m1, m2, m3 = st.columns(3)
        with m1:
            d_str = f"{delta_total:+.2f} ({prev_year} ëŒ€ë¹„)" if prev_year else None
            custom_metric(f"{latest_year} ì¢…í•© ì ìˆ˜", f"{curr_score:.2f}", d_str, show_arrow=True)
        with m2:
            d_top = get_delta_str(top_comp)
            val_top = f"{latest_series[top_comp]:.1f}" if top_comp != "-" else "-"
            custom_metric("ìµœê³  ê°•ì ", top_comp, f"{val_top} ({d_top})" if d_top else val_top, delta_color="normal", show_arrow=False)
        with m3:
            d_bot = get_delta_str(bot_comp)
            val_bot = f"{latest_series[bot_comp]:.1f}" if bot_comp != "-" else "-"
            custom_metric("ë³´ì™„ í•„ìš”", bot_comp, f"{val_bot} ({d_bot})" if d_bot else val_bot, delta_color="normal", show_arrow=False)
        
        st.divider()
        c1, c2 = st.columns([1, 1])
        with c1:
            st.markdown("##### ğŸ“… ë¦¬ë”ì‹­ ì¢…í•© ì ìˆ˜ ì¶”ì´")
            trend_df = pd.DataFrame({"Year": sorted_years, "Score": [avg_scores[y] for y in sorted_years]})
            fig_line = px.line(trend_df, x="Year", y="Score", markers=True, range_y=[0, 5.5], text="Score")
            fig_line.update_traces(line_color='#2563eb', line_width=3, textposition="top center", texttemplate='%{text:.2f}')
            st.plotly_chart(fig_line, use_container_width=True)
        with c2:
            st.markdown(f"##### ğŸ•¸ï¸ ë¦¬ë”ì‹­ ì˜ì—­ë³„ ë³€í™” ({latest_year})")
            fig_radar = go.Figure()
            colors = ['#cbd5e1', '#94a3b8', '#2563eb'] 
            cats = list(COMPETENCY_GROUPS.keys())
            for i, year in enumerate(sorted_years):
                vals = [grouped_scores[year].get(cat, 0) for cat in cats]
                vals += [vals[0]]
                fig_radar.add_trace(go.Scatterpolar(r=vals, theta=cats+[cats[0]], fill='toself' if year==latest_year else 'none', name=year, line_color=colors[i] if i<3 else 'black'))
            fig_radar.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 5])), showlegend=True)
            st.plotly_chart(fig_radar, use_container_width=True)

    # [TAB 2] ì£¼ê´€ì‹ ì‹¬ì¸µë¶„ì„
    with tab2:
        st.subheader("ğŸ“ ì£¼ê´€ì‹ í”¼ë“œë°± ì‹¬ì¸µ ë¶„ì„")
        
        # ë°ì´í„° ìˆ˜ì§‘
        data_context = ""
        
        data_context += "### [1] êµ¬ì„±ì› ì£¼ê´€ì‹ ì‘ë‹µ (3ê°œë…„)\n"
        for year in sorted_years:
            data_context += f"<{year}ë…„ êµ¬ì„±ì›>\n"
            if year in member_text_map:
                for col in member_text_map[year]:
                    val = leader_data[col]
                    if pd.notna(val) and str(val).strip() not in ["0", "-", ""]:
                        clean_col = col.replace(f"_{year}", "")
                        data_context += f"- {clean_col}: {val}\n"
        
        data_context += "\n### [2] ë™ë£Œ ì„ì› ì£¼ê´€ì‹ ì‘ë‹µ (3ê°œë…„)\n"
        for year in sorted_years:
            data_context += f"<{year}ë…„ ë™ë£Œ>\n"
            if year in peer_text_map:
                for col in peer_text_map[year]:
                    val = leader_data[col]
                    if pd.notna(val) and str(val).strip() not in ["0", "-", ""]:
                        clean_col = col.replace(f"_ë™ë£Œ_{year}", "")
                        data_context += f"- {clean_col}: {val}\n"
        
        data_context += "\n### [3] ê°ê´€ì‹ ì ìˆ˜ ë³€í™” ì¶”ì´\n"
        data_context += f"- ì¢…í•© ì ìˆ˜ ë³€í™”: {avg_scores}\n"
        data_context += f"- {latest_year}ë…„ ìµœê³  ê°•ì : {top_comp}, ë³´ì™„ í•„ìš”: {bot_comp}\n"

        if st.button("ğŸ¤– AI ì‹¬ì¸µ ë¶„ì„ ì‹¤í–‰"):
            if not OPENAI_API_KEY:
                st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                with st.spinner("AIê°€ 3ë…„ì¹˜ ë°ì´í„°ì™€ ì •ì„±/ì •ëŸ‰ ë°ì´í„°ë¥¼ í†µí•© ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        client = openai.OpenAI(api_key=OPENAI_API_KEY)
                        prompt = f"""
                        ë‹¹ì‹ ì€ ëŒ€ê¸°ì—… ì„ì› ë¦¬ë”ì‹­ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                        ì œê³µëœ 3ë…„ì¹˜ 'ê°ê´€ì‹ ì ìˆ˜'ì™€ 'ì£¼ê´€ì‹ ì½”ë©˜íŠ¸(êµ¬ì„±ì›/ë™ë£Œ)'ë¥¼ í†µí•© ë¶„ì„í•˜ì—¬ ì•„ë˜ 3ê°€ì§€ í•­ëª©ìœ¼ë¡œ ì‹¬ì¸µ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

                        1. **3ê°œë…„ ì£¼ê´€ì‹ í‚¤ì›Œë“œ ì£¼ìš” ë³€í™”**
                           - ì—°ë„ë³„ë¡œ ì£¼ê´€ì‹ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ê¸ì •/ë¶€ì • í‚¤ì›Œë“œê°€ ì–´ë–»ê²Œ ë‹¬ë¼ì¡ŒëŠ”ì§€ ë¶„ì„í•˜ì„¸ìš”.
                           - ì˜ˆ: "22ë…„ì—ëŠ” 'ì¶”ì§„ë ¥'ì´ ê°•ì¡°ë˜ì—ˆìœ¼ë‚˜, 24ë…„ì—ëŠ” 'ì†Œí†µ ë¶€ì¬'ê°€ í‚¤ì›Œë“œë¡œ ë¶€ìƒí•¨"

                        2. **ë³€í™” ì›ì¸ ì¶”ì  (ì •ëŸ‰+ì •ì„± í†µí•©)**
                           - ê°ê´€ì‹ ì ìˆ˜ì˜ ìƒìŠ¹/í•˜ë½ ì›ì¸ì„ ì£¼ê´€ì‹ ì½”ë©˜íŠ¸ì—ì„œ ì°¾ì•„ ì—°ê²°í•˜ì„¸ìš”.
                           - ì˜ˆ: "ì „ëµì  Insight ì ìˆ˜ê°€ í•˜ë½í•œ ì›ì¸ì€, êµ¬ì„±ì› ì½”ë©˜íŠ¸ì—ì„œ 'êµ¬ì²´ì  ë¹„ì „ ê³µìœ  ë¶€ì¡±'ì´ ë°˜ë³µ ì–¸ê¸‰ëœ ê²ƒê³¼ ì—°ê´€ë¨"

                        3. **êµ¬ì„±ì› vs ë™ë£Œ ì¸ì‹ ë¹„êµ**
                           - ë™ì¼í•œ ë¦¬ë”ì‹­ì— ëŒ€í•´ êµ¬ì„±ì›ê³¼ ë™ë£Œ ì„ì›ì´ ë°”ë¼ë³´ëŠ” ì‹œê° ì°¨ì´(Gap)ë¥¼ ë¶„ì„í•˜ì„¸ìš”.
                           - ì˜ˆ: "ë™ë£Œë“¤ì€ 'í˜‘ì—… ëŠ¥ë ¥'ì„ ë†’ê²Œ í‰ê°€í•˜ë‚˜, êµ¬ì„±ì›ë“¤ì€ 'íŒ€ ë‚´ ì†Œí†µ'ì„ ì•„ì‰¬ì›Œí•˜ëŠ” ê²½í–¥ì´ ìˆìŒ"

                        [ë¶„ì„ ëŒ€ìƒ ë°ì´í„°]
                        {data_context}
                        """
                        
                        res = client.chat.completions.create(
                            model="gpt-4o",
                            messages=[{"role": "user", "content": prompt}]
                        )
                        analysis = res.choices[0].message.content
                        st.success("ë¶„ì„ ì™„ë£Œ")
                        st.markdown(analysis)
                        st.session_state['qualitative_analysis'] = analysis 
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        with st.expander("ì›ë³¸ ë°ì´í„° ë³´ê¸°"):
            st.text(data_context)

    # [TAB 3] AI ì½”ì¹­
    with tab3:
        st.subheader("ğŸ’¬ AI ë¦¬ë”ì‹­ ì½”ì¹­")
        chat_container = st.container()
        
        if "messages" not in st.session_state:
            st.session_state.messages = []
            welcome = f"{selected_leader_name} ì„ì›ë‹˜, ë°˜ê°‘ìŠµë‹ˆë‹¤. 3ë…„ì¹˜ ë¦¬ë”ì‹­ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.\n\n"
            welcome += f"ìµœê·¼({latest_year}) ì¢…í•© ì ìˆ˜ëŠ” **{curr_score:.2f}ì **ì…ë‹ˆë‹¤. "
            if delta_total > 0: welcome += "ì „ë…„ ëŒ€ë¹„ ìƒìŠ¹ì„¸ì…ë‹ˆë‹¤. ğŸ“ˆ\n\n"
            elif delta_total < 0: welcome += "ì „ë…„ ëŒ€ë¹„ í•˜ë½ì„¸ê°€ ê´€ì°°ë©ë‹ˆë‹¤. ğŸ“‰\n\n"
            
            welcome += "í˜„ì¬ ê°€ì¥ ê³ ë¯¼ë˜ì‹œëŠ” ë¦¬ë”ì‹­ ì´ìŠˆëŠ” ë¬´ì—‡ì¸ê°€ìš”? í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì‹œë©´ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.\n\n"
            welcome += """---
            ğŸ’¡ **ì¶”ê°€ ì œì•ˆ (í´ë¦­í•˜ì—¬ ë³µì‚¬ í›„ ì§ˆë¬¸í•´ì£¼ì„¸ìš”)**
            * ğŸ“š **ì´ë¡  í•™ìŠµ:** í˜„ì¬ ì•½ì ê³¼ ê´€ë ¨ëœ ìµœì‹  ë¦¬ë”ì‹­ ì´ë¡  ì¶”ì²œ
            * ğŸ¬ **ì˜ìƒ ì¶”ì²œ:** ë¦¬ë”ì‹­ ê°œë°œì„ ìœ„í•œ TED ê°•ì—° ì¶”ì²œ
            * ğŸ—“ï¸ **W/S ì œì•ˆ:** ì¡°ì§ë¬¸í™” ê°œì„ ì„ ìœ„í•œ ì›Œí¬ìˆ ì•„ì  ë‹¤ ì œì•ˆ
            (ì›í•˜ì‹œëŠ” ë‚´ìš©ì„ ì§ˆë¬¸í•´ ì£¼ì‹œë©´ ìƒì„¸íˆ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤)
            """
            st.session_state.messages.append({"role": "assistant", "content": welcome})
            
        with chat_container:
            for msg in st.session_state.messages:
                with st.chat_message(msg["role"]):
                    st.write(msg["content"])
        
        if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with chat_container:
                with st.chat_message("user"):
                    st.write(prompt)
            
            if OPENAI_API_KEY:
                try:
                    client = openai.OpenAI(api_key=OPENAI_API_KEY)
                    qual_context = st.session_state.get('qualitative_analysis', "ì£¼ê´€ì‹ ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
                    
                    sys_msg = f"""
                    ë‹¹ì‹ ì€ ì„ì› ì „ìš© ë¦¬ë”ì‹­ ì½”ì¹˜ì…ë‹ˆë‹¤. ëŒ€ìƒ: {selected_leader_name}
                    [ë°ì´í„°] ì ìˆ˜: {avg_scores}, ê°•ì : {top_comp}, ì•½ì : {bot_comp}
                    [ì£¼ê´€ì‹ ë¶„ì„] {qual_context}
                    
                    [ê°€ì´ë“œ]
                    1. **ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜:** ê¹Šì´ ìˆëŠ” í†µì°° ì œê³µ.
                    2. **ì¶”ê°€ ì œì•ˆ:** í•„ìš” ì‹œ ì´ë¡ /ì˜ìƒ/ì›Œí¬ìˆ ì¶”ì²œ.
                    3. **Next Step:** ë‹µë³€ ëì— í•­ìƒ ì½”ì¹­ ì§ˆë¬¸(GROW ë“±)ì„ ë˜ì ¸ ëŒ€í™”ë¥¼ ì´ì–´ë‚˜ê°ˆ ê²ƒ. (ë¬¸êµ¬: í•´ë‹¹ ì§ˆë¬¸ì— ë‹µì„ í•´ì£¼ì‹œë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ì–´ë‚˜ê°€ ë³´ê² ìŠµë‹ˆë‹¤)
                    """
                    
                    msgs = [{"role": "system", "content": sys_msg}] + st.session_state.messages
                    
                    with chat_container:
                        with st.chat_message("assistant"):
                            stream = client.chat.completions.create(model="gpt-4o", messages=msgs, stream=True)
                            res = st.write_stream(stream)
                    st.session_state.messages.append({"role": "assistant", "content": res})
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: {e}")
            else:
                st.warning("API Key ë¯¸ì„¤ì •")

# --- ë°ì´í„°ê°€ ì—†ì„ ë•Œ (ì´ˆê¸° ëœë”© í™”ë©´) ---
else:
    # ë¹ˆ í™”ë©´ì„ ì±„ì›Œì¤„ ì•ˆë‚´ í˜ì´ì§€
    st.title("ğŸ‘‘ Executive Leadership AI Coach")
    st.markdown("---")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("""
        ### ğŸ“Š í”Œë«í¼ ì†Œê°œ
        ë³¸ í”Œë«í¼ì€ ì„ì› ë¦¬ë”ì‹­ ì§„ë‹¨ ê²°ê³¼(3ê°œë…„)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ê°ì ì¸ í†µì°°ê³¼ **ë§ì¶¤í˜• AI ì½”ì¹­**ì„ ì œê³µí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
        
        * **ì •ëŸ‰ ë°ì´í„° ì‹œê°í™”:** 3ë…„ì¹˜ ì ìˆ˜ íë¦„ ë° ì˜ì—­ë³„ ë°¸ëŸ°ìŠ¤ ë¶„ì„
        * **ì£¼ê´€ì‹ ì‹¬ì¸µ ë¶„ì„:** AIë¥¼ í†µí•œ êµ¬ì„±ì›/ë™ë£Œì˜ ì½”ë©˜íŠ¸ í•µì‹¬ ìš”ì•½
        * **AI ì½”ì¹˜ì™€ì˜ ëŒ€í™”:** ë°œê²¬ëœ ë¦¬ë”ì‹­ Gapì„ ê·¹ë³µí•˜ê¸° ìœ„í•œ 1:1 ì½”ì¹­
        """)
        
    with col2:
        st.info("""
        ### ğŸš€ ì‹œì‘í•˜ëŠ” ë°©ë²•
        1. ì¢Œì¸¡ ì‚¬ì´ë“œë°” ë©”ë‰´ì—ì„œ **[ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ]** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.
        2. ë¦¬ë”ì‹­ ì§„ë‹¨ ê²°ê³¼ê°€ í¬í•¨ëœ **ì—‘ì…€ íŒŒì¼(.xlsx)**ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
        3. ì—…ë¡œë“œê°€ ì™„ë£Œë˜ë©´, ë¶„ì„ ëŒ€ìƒì´ ë˜ëŠ” **ì„ì› ì´ë¦„ì„ ì„ íƒ**í•˜ì„¸ìš”.
        """)
        
    st.markdown("---")
    st.markdown("""
    #### ğŸ’¡ ë°ì´í„° í˜•ì‹ ì•ˆë‚´ (Excel)
    ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ì—‘ì…€ íŒŒì¼ì€ ì•„ë˜ì™€ ê°™ì€ ì»¬ëŸ¼ëª… íŒ¨í„´ì„ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
    - **êµ¬ì„±ì› ì‘ë‹µ (ì ìˆ˜/ì£¼ê´€ì‹):** `[ì—­ëŸ‰ëª…/ë¬¸í•­ëª…]_24ë…„` (ì˜ˆ: ì „ëµì  Insight_24ë…„)
    - **ë™ë£Œ ì‘ë‹µ (ì ìˆ˜/ì£¼ê´€ì‹):** `[ì—­ëŸ‰ëª…/ë¬¸í•­ëª…]_ë™ë£Œ_24ë…„` (ì˜ˆ: ì†Œí†µ_ë™ë£Œ_23ë…„)
    """)
