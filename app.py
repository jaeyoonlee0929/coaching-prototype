import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import openai
import re

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="Executive Leadership Coach",
    page_icon="ğŸ‘‘",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- API Key ì„¤ì • ---
try:
    OPENAI_API_KEY = st.secrets["JYL"]
except (FileNotFoundError, KeyError):
    OPENAI_API_KEY = None

# --- ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ---
@st.cache_data
def load_data(file):
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        return df
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def parse_columns(df):
    """
    ì»¬ëŸ¼ëª…ì„ ë¶„ì„í•˜ì—¬ ì—­ëŸ‰(Competency), ì—°ë„(Year), ë©”íƒ€ì •ë³´(Meta)ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    ê°€ì •: ì ìˆ˜ ì»¬ëŸ¼ì€ 'ì—­ëŸ‰ëª…_00ë…„' í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤.
    """
    score_cols = {} # {year: [col1, col2...]}
    text_cols = {}  # {year: [col1, col2...]}
    meta_cols = []
    
    # 2ìë¦¬ ì—°ë„(22, 23, 24) ë“±ì„ ì°¾ê¸° ìœ„í•œ ì •ê·œì‹
    # ì˜ˆ: "ì „ëµì  Insight_24ë…„" -> Group1: ì „ëµì  Insight, Group2: 24
    pattern = re.compile(r"^(.*)_(\d{2}ë…„)$")
    
    for col in df.columns:
        match = pattern.match(col)
        if match:
            item_name = match.group(1)
            year = match.group(2)
            
            # ë°ì´í„° íƒ€ì… í™•ì¸ (ìˆ˜ì¹˜í˜• vs ë¬¸ìí˜•)
            if pd.api.types.is_numeric_dtype(df[col]):
                if year not in score_cols: score_cols[year] = []
                score_cols[year].append(col)
            else:
                if year not in text_cols: text_cols[year] = []
                text_cols[year].append(col)
        else:
            meta_cols.append(col)
            
    return meta_cols, score_cols, text_cols

# --- ì‚¬ì´ë“œë°”: ì—…ë¡œë“œ ë° ëŒ€ìƒì ì„ íƒ ---
with st.sidebar:
    st.title("ğŸ‘‘ ì„ì› ë¦¬ë”ì‹­ ì½”ì¹­")
    st.info("3ê°œë…„ ë¦¬ë”ì‹­ ì§„ë‹¨ ê²°ê³¼(Excel)ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "csv"])
    
    selected_leader = None
    df = None
    
    if uploaded_file:
        df = load_data(uploaded_file)
        if df is not None:
            # ì´ë¦„ ì»¬ëŸ¼ ì°¾ê¸° (ì´ë¦„, ì„±ëª…, Name ë“±)
            name_col = next((c for c in df.columns if "ì´ë¦„" in c or "Name" in c), df.columns[1])
            
            # ë¦¬ë” ì„ íƒ
            leader_list = df[name_col].unique().tolist()
            selected_leader_name = st.selectbox("ëŒ€ìƒ ì„ì› ì„ íƒ", leader_list)
            
            # ì„ íƒëœ ë¦¬ë”ì˜ ë°ì´í„°ë§Œ í•„í„°ë§ (Series í˜•íƒœ)
            leader_data = df[df[name_col] == selected_leader_name].iloc[0]
            
            # API Key ê²½ê³ 
            if not OPENAI_API_KEY:
                st.warning("âš ï¸ API Key ë¯¸ì„¤ì • (AI ê¸°ëŠ¥ ì œí•œ)")

# --- ë©”ì¸ ë¡œì§ ---
if df is not None and selected_leader_name:
    # 1. ì»¬ëŸ¼ íŒŒì‹±
    meta_cols, score_map, text_map = parse_columns(df)
    
    # ì—°ë„ ì •ë ¬ (22ë…„ -> 23ë…„ -> 24ë…„)
    sorted_years = sorted(score_map.keys())
    
    # 2. ë°ì´í„° êµ¬ì¡°í™”
    # ì—­ëŸ‰ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ê°€ì¥ ìµœê·¼ ì—°ë„ ê¸°ì¤€)
    latest_year = sorted_years[-1]
    competencies = [col.replace(f"_{latest_year}", "") for col in score_map[latest_year]]
    
    # ì—°ë„ë³„ ì ìˆ˜ Dict ìƒì„±
    yearly_scores = {} # {22ë…„: {ì—­ëŸ‰: ì ìˆ˜, ...}, ...}
    
    for year in sorted_years:
        scores = {}
        for col in score_map[year]:
            comp_name = col.replace(f"_{year}", "")
            scores[comp_name] = leader_data[col]
        yearly_scores[year] = scores

    # --- UI íƒ­ êµ¬ì„± ---
    st.title(f"ğŸ“Š {selected_leader_name} ë‹˜ ë¦¬ë”ì‹­ ì§„ë‹¨ ë¶„ì„ (3ê°œë…„)")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ì¢…í•© ëŒ€ì‹œë³´ë“œ", "ğŸ“ ì£¼ê´€ì‹ ì‹¬ì¸µë¶„ì„", "ğŸ¤– AI ì½”ì¹­"])
    
    # [TAB 1] ì¢…í•© ëŒ€ì‹œë³´ë“œ
    with tab1:
        # 1-1. ìƒë‹¨ ì§€í‘œ (ìµœê·¼ ì—°ë„ ì¢…í•© ì ìˆ˜ ë° ì „ë…„ ëŒ€ë¹„ ì¦ê°)
        st.subheader("Overview")
        
        # ì—°ë„ë³„ í‰ê·  ì ìˆ˜ ê³„ì‚°
        avg_scores = {y: pd.Series(yearly_scores[y]).mean() for y in sorted_years}
        
        col1, col2, col3 = st.columns(3)
        current_score = avg_scores[latest_year]
        prev_year = sorted_years[-2] if len(sorted_years) > 1 else None
        prev_score = avg_scores[prev_year] if prev_year else 0
        delta = current_score - prev_score if prev_year else 0
        
        col1.metric(f"{latest_year} ì¢…í•© ì ìˆ˜", f"{current_score:.2f}", f"{delta:+.2f} ({prev_year} ëŒ€ë¹„)")
        
        # ìµœê³ /ìµœì € ì—­ëŸ‰
        latest_series = pd.Series(yearly_scores[latest_year])
        top_comp = latest_series.idxmax()
        bot_comp = latest_series.idxmin()
        
        col2.metric("ìµœê³  ê°•ì  ì—­ëŸ‰", top_comp, f"{latest_series[top_comp]:.1f}")
        col3.metric("ë³´ì™„ í•„ìš” ì—­ëŸ‰", bot_comp, f"{latest_series[bot_comp]:.1f}", delta_color="inverse")
        
        st.divider()
        
        # 1-2. ì°¨íŠ¸ ì˜ì—­
        c1, c2 = st.columns([1, 1])
        
        with c1:
            st.markdown("##### ğŸ“… 3ê°œë…„ ì¢…í•© ì ìˆ˜ ì¶”ì´")
            trend_df = pd.DataFrame({
                "Year": sorted_years,
                "Score": [avg_scores[y] for y in sorted_years]
            })
            fig_line = px.line(trend_df, x="Year", y="Score", markers=True, range_y=[0, 5.5])
            fig_line.update_traces(line_color='#2563eb', line_width=3)
            st.plotly_chart(fig_line, use_container_width=True)
            
        with c2:
            st.markdown("##### ğŸ•¸ï¸ ì—­ëŸ‰ë³„ ë³€í™” ë¹„êµ (Radar Chart)")
            # Radar Chart ë°ì´í„° êµ¬ì„±
            fig_radar = go.Figure()
            
            # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (ê³¼ê±° -> í˜„ì¬: ì—°í•œìƒ‰ -> ì§„í•œìƒ‰)
            colors = ['#cbd5e1', '#94a3b8', '#2563eb'] # Light Gray, Gray, Blue
            
            for i, year in enumerate(sorted_years):
                vals = [yearly_scores[year].get(comp, 0) for comp in competencies]
                # Radar ì°¨íŠ¸ ë‹«ê¸° ìœ„í•´ ì²« ë²ˆì§¸ ê°’ ì¶”ê°€
                vals += [vals[0]]
                comps_closed = competencies + [competencies[0]]
                
                fig_radar.add_trace(go.Scatterpolar(
                    r=vals,
                    theta=comps_closed,
                    fill='toself' if year == latest_year else 'none',
                    name=year,
                    line_color=colors[i] if i < 3 else 'black'
                ))
            
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True, range=[0, 5])),
                showlegend=True
            )
            st.plotly_chart(fig_radar, use_container_width=True)

    # [TAB 2] ì£¼ê´€ì‹ ì‹¬ì¸µë¶„ì„
    with tab2:
        st.subheader("ğŸ“ ì£¼ê´€ì‹ í”¼ë“œë°± ë¶„ì„")
        
        # ì£¼ê´€ì‹ ë°ì´í„° ìˆ˜ì§‘
        comments_text = ""
        for year in reversed(sorted_years): # ìµœì‹ ìˆœ
            if year in text_map:
                comments_text += f"\n[{year} í”¼ë“œë°±]\n"
                for col in text_map[year]:
                    val = leader_data[col]
                    if pd.notna(val) and str(val).strip() != "0":
                        clean_col_name = col.replace(f"_{year}", "")
                        comments_text += f"- {clean_col_name}: {val}\n"
        
        if not comments_text.strip():
            st.warning("ì£¼ê´€ì‹ ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # AI ë¶„ì„ ìš”ì²­ ë²„íŠ¼
            if st.button("ğŸ¤– AI ì‹¬ì¸µ ë¶„ì„ ì‹¤í–‰"):
                if not OPENAI_API_KEY:
                    st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    with st.spinner("AIê°€ 3ë…„ì¹˜ í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        try:
                            client = openai.OpenAI(api_key=OPENAI_API_KEY)
                            prompt = f"""
                            ë‹¹ì‹ ì€ ì„ì› ë¦¬ë”ì‹­ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                            ì•„ë˜ëŠ” íŠ¹ì • ì„ì›ì— ëŒ€í•œ 3ë…„ì¹˜ ì£¼ê´€ì‹ ë‹¤ë©´í‰ê°€ í”¼ë“œë°±ì…ë‹ˆë‹¤.
                            ì´ ë‚´ìš©ì„ ì •ë°€ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ 3ê°€ì§€ í•­ëª©ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
                            
                            1. **í•µì‹¬ ê°•ì  (Top 3)**: êµ¬ì²´ì ì¸ í–‰ë™ ì˜ˆì‹œì™€ í•¨ê»˜.
                            2. **ì£¼ìš” ë³´ì™„ì  ë° Risk**: ë°˜ë³µì ìœ¼ë¡œ ì–¸ê¸‰ë˜ê±°ë‚˜ ì¹˜ëª…ì ì¸ ì•½ì .
                            3. **ë³€í™” ì¶”ì´**: ê³¼ê±° ëŒ€ë¹„ ê°œì„ ëœ ì ì´ë‚˜ ìƒˆë¡­ê²Œ ëŒ€ë‘ëœ ì´ìŠˆ.
                            
                            [í”¼ë“œë°± ë°ì´í„°]
                            {comments_text}
                            """
                            
                            response = client.chat.completions.create(
                                model="gpt-4o",
                                messages=[{"role": "system", "content": "í•µì‹¬ë§Œ ëª…í™•í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”."},
                                          {"role": "user", "content": prompt}]
                            )
                            analysis_result = response.choices[0].message.content
                            st.success("ë¶„ì„ ì™„ë£Œ!")
                            st.markdown(analysis_result)
                            
                            # ì„¸ì…˜ì— ì €ì¥ (ì½”ì¹­ íƒ­ì—ì„œ ì“°ê¸° ìœ„í•´)
                            st.session_state['qualitative_analysis'] = analysis_result
                            
                        except Exception as e:
                            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
            # ì›ë³¸ ë°ì´í„° ë³´ê¸° (Expander)
            with st.expander("ì›ë³¸ í”¼ë“œë°± ì „ì²´ ë³´ê¸°"):
                st.text(comments_text)

    # [TAB 3] AI ì½”ì¹­
    with tab3:
        st.subheader("ğŸ’¬ AI ë¦¬ë”ì‹­ ì½”ì¹­")
        
        # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
        if "messages" not in st.session_state:
            st.session_state.messages = []
            # ì´ˆê¸° ì¸ì‚¬ ë©”ì‹œì§€ ìƒì„±
            welcome_msg = f"{selected_leader_name} ì„ì›ë‹˜, ë°˜ê°‘ìŠµë‹ˆë‹¤. 3ë…„ì¹˜ ë¦¬ë”ì‹­ ë°ì´í„°ë¥¼ ëª¨ë‘ íŒŒì•…í–ˆìŠµë‹ˆë‹¤.\n\n"
            
            # ë°ì´í„° ê¸°ë°˜ ì˜¤í”„ë‹ ë©˜íŠ¸ ìƒì„±
            if delta > 0:
                welcome_msg += f"ì‘ë…„ ëŒ€ë¹„ ì¢…í•© ì ìˆ˜ê°€ {delta:.2f}ì  ìƒìŠ¹í•˜ë©° ê¸ì •ì ì¸ ë³€í™”ë¥¼ ë³´ì´ê³  ê³„ì‹œêµ°ìš”. "
            elif delta < 0:
                welcome_msg += f"ì‘ë…„ ëŒ€ë¹„ ì¢…í•© ì ìˆ˜ê°€ ë‹¤ì†Œ í•˜ë½({delta:.2f}ì )í•˜ì—¬ ì ê²€ì´ í•„ìš”í•œ ì‹œì ì…ë‹ˆë‹¤. "
            
            welcome_msg += f"íŠ¹íˆ **'{top_comp}'** ì—­ëŸ‰ì€ ë§¤ìš° íƒì›”í•˜ì§€ë§Œ, **'{bot_comp}'** ì—­ëŸ‰ì€ ë³´ì™„ì´ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤.\n\nì–´ë–¤ ë¶€ë¶„ë¶€í„° ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ì‹œê² ìŠµë‹ˆê¹Œ?"
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})

        # ì±„íŒ… UI
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]):
                st.write(msg["content"])
        
        if prompt := st.chat_input("ì½”ì¹˜ì—ê²Œ ì§ˆë¬¸í•˜ê¸°..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)
            
            if OPENAI_API_KEY:
                try:
                    client = openai.OpenAI(api_key=OPENAI_API_KEY)
                    
                    # ì£¼ê´€ì‹ ë¶„ì„ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
                    qual_context = st.session_state.get('qualitative_analysis', "ì£¼ê´€ì‹ ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
                    
                    system_prompt = f"""
                    ë‹¹ì‹ ì€ ëŒ€ê¸°ì—… ì„ì› ì „ìš© ë¦¬ë”ì‹­ ì½”ì¹˜(Executive Coach)ì…ë‹ˆë‹¤.
                    ì‚¬ìš©ì ì •ë³´: {selected_leader_name} ì„ì›
                    
                    [ì •ëŸ‰ ë°ì´í„°]
                    - 3ë…„ì¹˜ ì ìˆ˜ ì¶”ì´: {avg_scores}
                    - ìµœì‹  ê°•ì : {top_comp}, ì•½ì : {bot_comp}
                    
                    [ì •ì„± í”¼ë“œë°± ìš”ì•½]
                    {qual_context}
                    
                    [ì½”ì¹­ ê°€ì´ë“œ]
                    1. ì„ì›ê¸‰ì— ë§ëŠ” í’ˆê²© ìˆê³  ì§ê´€ì ì¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
                    2. ë‹¨ìˆœíˆ ì ìˆ˜ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , 'ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸' ê´€ì ì—ì„œ í•´ì„í•´ ì£¼ì„¸ìš”.
                    3. ì•½ì ì— ëŒ€í•´ì„œëŠ” ë°©ì–´ê¸°ì œë¥¼ ê±´ë“œë¦¬ì§€ ë§ê³ , 'ë” í° ë¦¬ë”ë¡œ ì„±ì¥í•˜ê¸° ìœ„í•œ ì œì–¸' í˜•íƒœë¡œ ì „ë‹¬í•˜ì„¸ìš”.
                    4. GROW ëª¨ë¸ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì ìš©í•˜ì—¬ ì‹¤í–‰ ê³„íšì„ ì´ëŒì–´ë‚´ì„¸ìš”.
                    """
                    
                    msgs = [{"role": "system", "content": system_prompt}] + st.session_state.messages
                    
                    with st.chat_message("assistant"):
                        stream = client.chat.completions.create(model="gpt-4o", messages=msgs, stream=True)
                        response = st.write_stream(stream)
                    
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: {e}")
            else:
                st.warning("API Key ë¯¸ì„¤ì •")
