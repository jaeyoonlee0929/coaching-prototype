import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import openai
import re

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="Executive Leadership Coach",
    page_icon="ğŸ‘‘",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- API Key ì„¤ì • ---
try:
    OPENAI_API_KEY = st.secrets["JYL"]
except (FileNotFoundError, KeyError):
    OPENAI_API_KEY = None

# --- ì—­ëŸ‰ ê·¸ë£¹ ì •ì˜ (ì‚¬ìš©ì ìš”ì²­ ê¸°ì¤€) ---
COMPETENCY_GROUPS = {
    "SKMSì— ëŒ€í•œ í™•ì‹ ê³¼ ì—´ì •": [
        "SKMSì— ëŒ€í•œ í™•ì‹ ",
        "êµ¬ì„±ì›/ì´í•´ê´€ê³„ì í–‰ë³µ ì¶”êµ¬",
        "íŒ¨ê¸°/ì†”ì„ ìˆ˜ë²”",
        "Integrity"
    ],
    "í˜ì‹ ì  ì „ëµ ìˆ˜ë¦½": [
        "ì „ëµì  Insight",
        "ë‹´ë‹¹ ì¡°ì§ ë³€í™” Design",
        "ë¹„ì „ ê³µìœ /ì§€ì†ì  ë³€í™” ì¶”ì§„"
    ],
    "ê³¼ê°í•œ ëŒíŒŒì™€ ì‹¤í–‰": [
        "SUPEX ëª©í‘œ ì„¤ì •",
        "ë‚´Â·ì™¸ë¶€ í­ë„“ì€ í˜‘ì—…", 
        "ì‹ ì†í•œ ì‹¤í–‰ ë° ì„±ê³¼ ì°½ì¶œ"
    ],
    "VWBE ë¬¸í™”êµ¬ì¶•": [
        "êµ¬ì„±ì› VWBEí™˜ê²½ ì¡°ì„± í™œë™ ì§€ì›",
        "ì‹ ë¢° ê¸°ë°˜ì˜ í˜‘ë ¥ ì´‰ì§„",
        "íŒ¨ê¸° ì¸ì¬ ì¸ì •/ìœ¡ì„±"
    ]
}

# --- ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ---
@st.cache_data
def load_data(file):
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        return df
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def normalize_text(text):
    """í…ìŠ¤íŠ¸ ë§¤ì¹­ì„ ìœ„í•´ ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    return re.sub(r'[\s\Â·\.\,\-\_]', '', str(text)).lower()

def parse_columns(df):
    """
    ì»¬ëŸ¼ëª…ì„ ë¶„ì„í•˜ì—¬ êµ¬ì„±ì› ì‘ë‹µ, ë™ë£Œ ì‘ë‹µ, í…ìŠ¤íŠ¸ ë°ì´í„° ë“±ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    """
    member_scores = {} # {year: [col1, col2...]}
    peer_scores = {}   # {year: [col1, col2...]}
    text_cols = {}     # {year: [col1, col2...]}
    meta_cols = []
    
    peer_pattern = re.compile(r"^(.*)_ë™ë£Œ_(\d{2}ë…„)$")
    member_pattern = re.compile(r"^(.*)_(\d{2}ë…„)$")
    
    for col in df.columns:
        peer_match = peer_pattern.match(col)
        if peer_match:
            year = peer_match.group(2)
            if pd.api.types.is_numeric_dtype(df[col]):
                if year not in peer_scores: peer_scores[year] = []
                peer_scores[year].append(col)
            continue
            
        member_match = member_pattern.match(col)
        if member_match:
            year = member_match.group(2)
            if pd.api.types.is_numeric_dtype(df[col]):
                if year not in member_scores: member_scores[year] = []
                member_scores[year].append(col)
            else:
                if year not in text_cols: text_cols[year] = []
                text_cols[year].append(col)
        else:
            meta_cols.append(col)
            
    return meta_cols, member_scores, peer_scores, text_cols

# --- ì‚¬ì´ë“œë°”: ì—…ë¡œë“œ ë° ëŒ€ìƒì ì„ íƒ ---
with st.sidebar:
    st.title("ğŸ‘‘ ì„ì› ë¦¬ë”ì‹­ ì½”ì¹­")
    st.info("3ê°œë…„ ë¦¬ë”ì‹­ ì§„ë‹¨ ê²°ê³¼(Excel)ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "csv"])
    
    selected_leader = None
    df = None
    
    if uploaded_file:
        df = load_data(uploaded_file)
        if df is not None:
            name_col = next((c for c in df.columns if "ì´ë¦„" in c or "Name" in c), df.columns[1])
            leader_list = df[name_col].unique().tolist()
            selected_leader_name = st.selectbox("ëŒ€ìƒ ì„ì› ì„ íƒ", leader_list)
            leader_data = df[df[name_col] == selected_leader_name].iloc[0]
            
            if not OPENAI_API_KEY:
                st.warning("âš ï¸ API Key ë¯¸ì„¤ì • (AI ê¸°ëŠ¥ ì œí•œ)")

# --- ë©”ì¸ ë¡œì§ ---
if df is not None and selected_leader_name:
    # 1. ì»¬ëŸ¼ íŒŒì‹±
    meta_cols, member_map, peer_map, text_map = parse_columns(df)
    sorted_years = sorted(member_map.keys())
    latest_year = sorted_years[-1]
    
    # 2. ì—­ëŸ‰ ë§¤í•‘ ë° ë°ì´í„° ì¶”ì¶œ
    raw_competencies = [col.replace(f"_{latest_year}", "") for col in member_map[latest_year]]
    norm_comp_map = {normalize_text(c): c for c in raw_competencies}
    
    grouped_scores = {}
    detailed_scores = {} 

    for year in sorted_years:
        year_group_data = {}
        year_detail_data = {}
        
        # ìƒì„¸ ì ìˆ˜ ì¶”ì¶œ (0ì  ì œì™¸ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥)
        for col in member_map[year]:
            if "_ë™ë£Œ_" in col: continue
            comp_name = col.replace(f"_{year}", "")
            val = leader_data[col]
            # ìœ íš¨í•œ ì ìˆ˜ë§Œ ì €ì¥ (NaNì´ë‚˜ 0 ì œì™¸)
            if pd.notna(val) and val > 0:
                year_detail_data[comp_name] = val
            else:
                year_detail_data[comp_name] = 0 # ê³„ì‚°ì„ ìœ„í•´ 0ìœ¼ë¡œ ë‘ 
        detailed_scores[year] = year_detail_data
        
        # ê·¸ë£¹ë³„ í‰ê·  ê³„ì‚°
        for group_name, sub_items in COMPETENCY_GROUPS.items():
            scores = []
            for item in sub_items:
                norm_item = normalize_text(item)
                target_col = None
                if item in year_detail_data:
                    target_col = item
                elif norm_item in norm_comp_map and norm_comp_map[norm_item] in year_detail_data:
                    target_col = norm_comp_map[norm_item]
                
                if target_col:
                    val = year_detail_data[target_col]
                    if val > 0: # 0ì ì€ í‰ê·  ê³„ì‚°ì—ì„œ ì œì™¸
                        scores.append(val)
            
            if scores:
                year_group_data[group_name] = sum(scores) / len(scores)
            else:
                year_group_data[group_name] = 0.0
        
        grouped_scores[year] = year_group_data

    # --- UI íƒ­ êµ¬ì„± ---
    st.title(f"ğŸ“Š {selected_leader_name} ë‹˜ ë¦¬ë”ì‹­ ì§„ë‹¨ ë¶„ì„ (3ê°œë…„)")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ì¢…í•© ëŒ€ì‹œë³´ë“œ", "ğŸ“ ì£¼ê´€ì‹ ì‹¬ì¸µë¶„ì„", "ğŸ¤– AI ì½”ì¹­"])
    
    # [TAB 1] ì¢…í•© ëŒ€ì‹œë³´ë“œ
    with tab1:
        st.subheader("Overview (êµ¬ì„±ì› ì‘ë‹µ ê¸°ì¤€)")
        
        # 1-1. ìƒë‹¨ ì§€í‘œ ê³„ì‚°
        # ì—°ë„ë³„ í‰ê·  ì ìˆ˜ (0ì  ì œì™¸í•˜ê³  ê³„ì‚°)
        avg_scores = {}
        for y in sorted_years:
            vals = [v for v in detailed_scores[y].values() if v > 0]
            avg_scores[y] = sum(vals) / len(vals) if vals else 0

        curr_score = avg_scores[latest_year]
        prev_year = sorted_years[-2] if len(sorted_years) > 1 else None
        
        delta_total = (curr_score - avg_scores[prev_year]) if prev_year else 0
        
        # ê°•ì /ì•½ì  (ìµœì‹ )
        latest_series = pd.Series(detailed_scores[latest_year])
        latest_series = latest_series[latest_series > 0] # 0ì  ì œì™¸
        
        if not latest_series.empty:
            top_comp = latest_series.idxmax()
            bot_comp = latest_series.idxmin()
        else:
            top_comp, bot_comp = "-", "-"

        # ì§€í‘œ ì¶œë ¥ (3 Columns: ì¢…í•© / ìµœê³  ê°•ì  / ë³´ì™„ í•„ìš”)
        m1, m2, m3 = st.columns(3)
        
        m1.metric(f"{latest_year} ì¢…í•© ì ìˆ˜", f"{curr_score:.2f}", f"{delta_total:+.2f} ({prev_year} ëŒ€ë¹„)")
        m2.metric("ìµœê³  ê°•ì ", top_comp, f"{latest_series[top_comp]:.1f}" if top_comp != "-" else "-")
        m3.metric("ë³´ì™„ í•„ìš”", bot_comp, f"{latest_series[bot_comp]:.1f}" if bot_comp != "-" else "-", delta_color="inverse")
        
        st.divider()
        
        # 1-2. ì°¨íŠ¸ ì˜ì—­
        c1, c2 = st.columns([1, 1])
        
        with c1:
            st.markdown("##### ğŸ“… 3ê°œë…„ ì¢…í•© ì ìˆ˜ ì¶”ì´")
            trend_df = pd.DataFrame({
                "Year": sorted_years,
                "Score": [avg_scores[y] for y in sorted_years]
            })
            # text="Score" ì¶”ê°€: ì ìˆ˜ ë ˆì´ë¸” í‘œì‹œ
            fig_line = px.line(trend_df, x="Year", y="Score", markers=True, range_y=[0, 5.5], text="Score")
            fig_line.update_traces(line_color='#2563eb', line_width=3, textposition="top center", texttemplate='%{text:.2f}')
            st.plotly_chart(fig_line, use_container_width=True)
            
        with c2:
            st.markdown(f"##### ğŸ•¸ï¸ ë¦¬ë”ì‹­ ì˜ì—­ë³„ ë³€í™” ({latest_year})")
            fig_radar = go.Figure()
            colors = ['#cbd5e1', '#94a3b8', '#2563eb'] # ì—°í•œìƒ‰ -> ì§„í•œìƒ‰
            
            categories = list(COMPETENCY_GROUPS.keys())
            
            for i, year in enumerate(sorted_years):
                vals = [grouped_scores[year].get(cat, 0) for cat in categories]
                vals += [vals[0]] # Close loop
                cats_closed = categories + [categories[0]]
                
                fig_radar.add_trace(go.Scatterpolar(
                    r=vals,
                    theta=cats_closed,
                    fill='toself' if year == latest_year else 'none',
                    name=year,
                    line_color=colors[i] if i < 3 else 'black'
                ))
            
            fig_radar.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 5])), showlegend=True)
            st.plotly_chart(fig_radar, use_container_width=True)

    # [TAB 2] ì£¼ê´€ì‹ ì‹¬ì¸µë¶„ì„
    with tab2:
        st.subheader("ğŸ“ ì£¼ê´€ì‹ í”¼ë“œë°± ë¶„ì„")
        
        comments_text = ""
        for year in reversed(sorted_years):
            if year in text_map:
                comments_text += f"\n[{year} í”¼ë“œë°±]\n"
                for col in text_map[year]:
                    val = leader_data[col]
                    if pd.notna(val) and str(val).strip() not in ["0", "-", ""]:
                        clean_col = col.replace(f"_{year}", "")
                        comments_text += f"- {clean_col}: {val}\n"
        
        if not comments_text.strip():
            st.warning("ë¶„ì„í•  ì£¼ê´€ì‹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            if st.button("ğŸ¤– AI ì‹¬ì¸µ ë¶„ì„ ì‹¤í–‰"):
                if not OPENAI_API_KEY:
                    st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    with st.spinner("AI ë¶„ì„ ì¤‘..."):
                        try:
                            client = openai.OpenAI(api_key=OPENAI_API_KEY)
                            prompt = f"""
                            ë‹¹ì‹ ì€ ì„ì› ë¦¬ë”ì‹­ ì½”ì¹˜ì…ë‹ˆë‹¤. 3ë…„ì¹˜ ì£¼ê´€ì‹ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìš”ì•½í•´ì£¼ì„¸ìš”.
                            
                            1. **í•µì‹¬ ê°•ì  (Top 3)**
                            2. **ì£¼ìš” ë³´ì™„ì  ë° Risk**
                            3. **ì—°ë„ë³„ ë³€í™” íë¦„**
                            
                            [ë°ì´í„°]
                            {comments_text}
                            """
                            res = client.chat.completions.create(
                                model="gpt-4o",
                                messages=[{"role": "user", "content": prompt}]
                            )
                            analysis = res.choices[0].message.content
                            st.success("ë¶„ì„ ì™„ë£Œ")
                            st.markdown(analysis)
                            st.session_state['qualitative_analysis'] = analysis
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜: {e}")
            
            with st.expander("ì›ë³¸ ë°ì´í„° ë³´ê¸°"):
                st.text(comments_text)

    # [TAB 3] AI ì½”ì¹­
    with tab3:
        st.subheader("ğŸ’¬ AI ë¦¬ë”ì‹­ ì½”ì¹­")
        
        chat_container = st.container()
        
        if "messages" not in st.session_state:
            st.session_state.messages = []
            welcome = f"{selected_leader_name} ì„ì›ë‹˜, ë°˜ê°‘ìŠµë‹ˆë‹¤.\n\n"
            welcome += f"ìµœê·¼({latest_year}) êµ¬ì„±ì› í‰ê°€ ê¸°ì¤€ ì¢…í•© ì ìˆ˜ëŠ” **{curr_score:.2f}ì **ì…ë‹ˆë‹¤. "
            if delta > 0: welcome += "ì „ë…„ ëŒ€ë¹„ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤. ğŸ“ˆ"
            elif delta < 0: welcome += "ì „ë…„ ëŒ€ë¹„ ë‹¤ì†Œ í•˜ë½í–ˆìŠµë‹ˆë‹¤. ğŸ“‰"
            
            st.session_state.messages.append({"role": "assistant", "content": welcome})
            
        with chat_container:
            for msg in st.session_state.messages:
                with st.chat_message(msg["role"]):
                    st.write(msg["content"])
        
        if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with chat_container:
                with st.chat_message("user"):
                    st.write(prompt)
            
            if OPENAI_API_KEY:
                try:
                    client = openai.OpenAI(api_key=OPENAI_API_KEY)
                    qual_context = st.session_state.get('qualitative_analysis', "")
                    
                    sys_msg = f"""
                    ë‹¹ì‹ ì€ ì„ì› ì „ìš© ì½”ì¹˜ì…ë‹ˆë‹¤.
                    ëŒ€ìƒ: {selected_leader_name}
                    ì •ëŸ‰ ë°ì´í„°(êµ¬ì„±ì› ê¸°ì¤€): {avg_scores}
                    ê°•ì : {top_comp}, ì•½ì : {bot_comp}
                    ì£¼ê´€ì‹ ë¶„ì„: {qual_context}
                    
                    GROW ëª¨ë¸ë¡œ ì½”ì¹­í•˜ê³ , ì„ì›ì˜ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
                    """
                    
                    msgs = [{"role": "system", "content": sys_msg}] + st.session_state.messages
                    
                    with chat_container:
                        with st.chat_message("assistant"):
                            stream = client.chat.completions.create(model="gpt-4o", messages=msgs, stream=True)
                            res = st.write_stream(stream)
                    st.session_state.messages.append({"role": "assistant", "content": res})
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: {e}")
            else:
                st.warning("API Key ë¯¸ì„¤ì •")
