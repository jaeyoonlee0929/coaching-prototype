import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import openai
import re

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="Executive Leadership Coach",
    page_icon="ğŸ‘‘",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- API Key ì„¤ì • ---
try:
    OPENAI_API_KEY = st.secrets["JYL"]
except (FileNotFoundError, KeyError):
    OPENAI_API_KEY = None

# --- ì—­ëŸ‰ ê·¸ë£¹ ì •ì˜ (ì‚¬ìš©ì ìš”ì²­ ê¸°ì¤€) ---
COMPETENCY_GROUPS = {
    "SKMSì— ëŒ€í•œ í™•ì‹ ê³¼ ì—´ì •": [
        "SKMSì— ëŒ€í•œ í™•ì‹ ",
        "êµ¬ì„±ì›/ì´í•´ê´€ê³„ì í–‰ë³µ ì¶”êµ¬",
        "íŒ¨ê¸°/ì†”ì„ ìˆ˜ë²”",
        "Integrity"
    ],
    "í˜ì‹ ì  ì „ëµ ìˆ˜ë¦½": [
        "ì „ëµì  Insight",
        "ë‹´ë‹¹ ì¡°ì§ ë³€í™” Design",
        "ë¹„ì „ ê³µìœ /ì§€ì†ì  ë³€í™” ì¶”ì§„"
    ],
    "ê³¼ê°í•œ ëŒíŒŒì™€ ì‹¤í–‰": [
        "SUPEX ëª©í‘œ ì„¤ì •",
        "ë‚´Â·ì™¸ë¶€ í­ë„“ì€ í˜‘ì—…", 
        "ì‹ ì†í•œ ì‹¤í–‰ ë° ì„±ê³¼ ì°½ì¶œ"
    ],
    "VWBE ë¬¸í™”êµ¬ì¶•": [
        "êµ¬ì„±ì› VWBEí™˜ê²½ ì¡°ì„± í™œë™ ì§€ì›",
        "ì‹ ë¢° ê¸°ë°˜ì˜ í˜‘ë ¥ ì´‰ì§„",
        "íŒ¨ê¸° ì¸ì¬ ì¸ì •/ìœ¡ì„±"
    ]
}

# --- ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ---
@st.cache_data
def load_data(file):
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file)
        else:
            df = pd.read_excel(file)
        return df
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def normalize_text(text):
    """í…ìŠ¤íŠ¸ ë§¤ì¹­ì„ ìœ„í•´ ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    return re.sub(r'[\s\Â·\.\,\-\_]', '', str(text)).lower()

def parse_columns(df):
    """
    ì»¬ëŸ¼ëª…ì„ ë¶„ì„í•˜ì—¬ êµ¬ì„±ì› ì‘ë‹µ, ë™ë£Œ ì‘ë‹µ, í…ìŠ¤íŠ¸ ë°ì´í„° ë“±ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    """
    member_scores = {} # {year: [col1, col2...]}
    peer_scores = {}   # {year: [col1, col2...]}
    text_cols = {}     # {year: [col1, col2...]}
    meta_cols = []
    
    peer_pattern = re.compile(r"^(.*)_ë™ë£Œ_(\d{2}ë…„)$")
    member_pattern = re.compile(r"^(.*)_(\d{2}ë…„)$")
    
    for col in df.columns:
        peer_match = peer_pattern.match(col)
        if peer_match:
            year = peer_match.group(2)
            if pd.api.types.is_numeric_dtype(df[col]):
                if year not in peer_scores: peer_scores[year] = []
                peer_scores[year].append(col)
            continue
            
        member_match = member_pattern.match(col)
        if member_match:
            year = member_match.group(2)
            if pd.api.types.is_numeric_dtype(df[col]):
                if year not in member_scores: member_scores[year] = []
                member_scores[year].append(col)
            else:
                if year not in text_cols: text_cols[year] = []
                text_cols[year].append(col)
        else:
            meta_cols.append(col)
            
    return meta_cols, member_scores, peer_scores, text_cols

# --- ì‚¬ì´ë“œë°”: ì—…ë¡œë“œ ë° ëŒ€ìƒì ì„ íƒ ---
with st.sidebar:
    st.title("ğŸ‘‘ ì„ì› ë¦¬ë”ì‹­ ì½”ì¹­")
    st.info("3ê°œë…„ ë¦¬ë”ì‹­ ì§„ë‹¨ ê²°ê³¼(Excel)ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "csv"])
    
    selected_leader = None
    df = None
    
    if uploaded_file:
        df = load_data(uploaded_file)
        if df is not None:
            name_col = next((c for c in df.columns if "ì´ë¦„" in c or "Name" in c), df.columns[1])
            leader_list = df[name_col].unique().tolist()
            selected_leader_name = st.selectbox("ëŒ€ìƒ ì„ì› ì„ íƒ", leader_list)
            leader_data = df[df[name_col] == selected_leader_name].iloc[0]
            
            if not OPENAI_API_KEY:
                st.warning("âš ï¸ API Key ë¯¸ì„¤ì • (AI ê¸°ëŠ¥ ì œí•œ)")

# --- ë©”ì¸ ë¡œì§ ---
if df is not None and selected_leader_name:
    # 1. ì»¬ëŸ¼ íŒŒì‹±
    meta_cols, member_map, peer_map, text_map = parse_columns(df)
    sorted_years = sorted(member_map.keys())
    latest_year = sorted_years[-1]
    
    # 2. ì—­ëŸ‰ ë§¤í•‘ ë° ë°ì´í„° ì¶”ì¶œ
    raw_competencies = [col.replace(f"_{latest_year}", "") for col in member_map[latest_year]]
    norm_comp_map = {normalize_text(c): c for c in raw_competencies}
    
    grouped_scores = {}
    detailed_scores = {} 

    for year in sorted_years:
        year_group_data = {}
        year_detail_data = {}
        
        # ìƒì„¸ ì ìˆ˜ ì¶”ì¶œ
        for col in member_map[year]:
            if "_ë™ë£Œ_" in col: continue
            comp_name = col.replace(f"_{year}", "")
            val = leader_data[col]
            if pd.notna(val) and val > 0:
                year_detail_data[comp_name] = val
            else:
                year_detail_data[comp_name] = 0
        detailed_scores[year] = year_detail_data
        
        # ê·¸ë£¹ë³„ í‰ê·  ê³„ì‚°
        for group_name, sub_items in COMPETENCY_GROUPS.items():
            scores = []
            for item in sub_items:
                norm_item = normalize_text(item)
                target_col = None
                if item in year_detail_data:
                    target_col = item
                elif norm_item in norm_comp_map and norm_comp_map[norm_item] in year_detail_data:
                    target_col = norm_comp_map[norm_item]
                
                if target_col:
                    val = year_detail_data[target_col]
                    if val > 0:
                        scores.append(val)
            
            if scores:
                year_group_data[group_name] = sum(scores) / len(scores)
            else:
                year_group_data[group_name] = 0.0
        
        grouped_scores[year] = year_group_data

    # Common calculations
    avg_scores = {}
    for y in sorted_years:
        vals = [v for v in detailed_scores[y].values() if v > 0]
        avg_scores[y] = sum(vals) / len(vals) if vals else 0

    curr_score = avg_scores[latest_year]
    prev_year = sorted_years[-2] if len(sorted_years) > 1 else None
    
    delta_total = (curr_score - avg_scores[prev_year]) if prev_year else 0
    
    latest_series = pd.Series(detailed_scores[latest_year])
    latest_series = latest_series[latest_series > 0]
    
    if not latest_series.empty:
        top_comp = latest_series.idxmax()
        bot_comp = latest_series.idxmin()
    else:
        top_comp, bot_comp = "-", "-"

    # ê°œë³„ ì—­ëŸ‰ Delta ê³„ì‚°ì„ ìœ„í•œ ì¤€ë¹„
    def get_comp_delta(comp_name):
        if not prev_year: return None
        prev_val = detailed_scores[prev_year].get(comp_name, 0)
        curr_val = detailed_scores[latest_year].get(comp_name, 0)
        if prev_val > 0 and curr_val > 0:
            return curr_val - prev_val
        return None

    # --- UI íƒ­ êµ¬ì„± ---
    st.title(f"ğŸ“Š {selected_leader_name} ë‹˜ ë¦¬ë”ì‹­ ì§„ë‹¨ ë¶„ì„ (3ê°œë…„)")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ ì¢…í•© ëŒ€ì‹œë³´ë“œ", "ğŸ“ ì£¼ê´€ì‹ ì‹¬ì¸µë¶„ì„", "ğŸ¤– AI ì½”ì¹­"])
    
    # [TAB 1] ì¢…í•© ëŒ€ì‹œë³´ë“œ
    with tab1:
        st.subheader("Overview (êµ¬ì„±ì› ì‘ë‹µ ê¸°ì¤€)")
        
        m1, m2, m3 = st.columns(3)
        
        m1.metric(f"{latest_year} ì¢…í•© ì ìˆ˜", f"{curr_score:.2f}", f"{delta_total:+.2f} ({prev_year} ëŒ€ë¹„)")
        
        # ê°•ì  Metric
        delta_top = get_comp_delta(top_comp)
        delta_top_str = f"{delta_top:+.1f}" if delta_top is not None else None
        m2.metric("ìµœê³  ê°•ì ", top_comp, f"{latest_series[top_comp]:.1f}", delta=delta_top_str)
        
        # ì•½ì  Metric (Delta ìƒ‰ìƒì„ inverseë¡œ í•˜ì—¬ í•˜ë½ ì‹œ ë¹¨ê°•, ìƒìŠ¹ ì‹œ ì´ˆë¡...ì´ ì•„ë‹ˆë¼ ì•½ì ì€ ì ìˆ˜ê°€ ë‚®ì€ ê²ƒì´ë‹ˆ)
        # ë³´í†µ ì ìˆ˜ëŠ” ì˜¤ë¥´ë©´ ì¢‹ìŒ(Green). ì•½ì ì´ë¼ë„ ì ìˆ˜ê°€ ì˜¬ëìœ¼ë©´ Greenì´ ë§ìŒ.
        # ë”°ë¼ì„œ delta_color="normal" (ê¸°ë³¸ê°’) ì‚¬ìš©
        delta_bot = get_comp_delta(bot_comp)
        delta_bot_str = f"{delta_bot:+.1f}" if delta_bot is not None else None
        m3.metric("ë³´ì™„ í•„ìš”", bot_comp, f"{latest_series[bot_comp]:.1f}", delta=delta_bot_str)
        
        st.divider()
        
        # ì°¨íŠ¸ ì˜ì—­
        c1, c2 = st.columns([1, 1])
        
        with c1:
            st.markdown("##### ğŸ“… 3ê°œë…„ ì¢…í•© ì ìˆ˜ ì¶”ì´")
            trend_df = pd.DataFrame({
                "Year": sorted_years,
                "Score": [avg_scores[y] for y in sorted_years]
            })
            fig_line = px.line(trend_df, x="Year", y="Score", markers=True, range_y=[0, 5.5], text="Score")
            fig_line.update_traces(line_color='#2563eb', line_width=3, textposition="top center", texttemplate='%{text:.2f}')
            st.plotly_chart(fig_line, use_container_width=True)
            
        with c2:
            st.markdown(f"##### ğŸ•¸ï¸ ë¦¬ë”ì‹­ ì˜ì—­ë³„ ë³€í™” ({latest_year})")
            fig_radar = go.Figure()
            colors = ['#cbd5e1', '#94a3b8', '#2563eb'] # ì—°í•œìƒ‰ -> ì§„í•œìƒ‰
            
            categories = list(COMPETENCY_GROUPS.keys())
            
            for i, year in enumerate(sorted_years):
                vals = [grouped_scores[year].get(cat, 0) for cat in categories]
                vals += [vals[0]]
                cats_closed = categories + [categories[0]]
                
                fig_radar.add_trace(go.Scatterpolar(
                    r=vals,
                    theta=cats_closed,
                    fill='toself' if year == latest_year else 'none',
                    name=year,
                    line_color=colors[i] if i < 3 else 'black'
                ))
            
            fig_radar.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 5])), showlegend=True)
            st.plotly_chart(fig_radar, use_container_width=True)

    # [TAB 2] ì£¼ê´€ì‹ ì‹¬ì¸µë¶„ì„
    with tab2:
        st.subheader("ğŸ“ ì£¼ê´€ì‹ í”¼ë“œë°± ë¶„ì„")
        
        comments_text = ""
        for year in reversed(sorted_years):
            if year in text_map:
                comments_text += f"\n[{year} í”¼ë“œë°±]\n"
                for col in text_map[year]:
                    val = leader_data[col]
                    if pd.notna(val) and str(val).strip() not in ["0", "-", ""]:
                        clean_col = col.replace(f"_{year}", "")
                        comments_text += f"- {clean_col}: {val}\n"
        
        if not comments_text.strip():
            st.warning("ë¶„ì„í•  ì£¼ê´€ì‹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            if st.button("ğŸ¤– AI ì‹¬ì¸µ ë¶„ì„ ì‹¤í–‰"):
                if not OPENAI_API_KEY:
                    st.error("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    with st.spinner("AI ë¶„ì„ ì¤‘..."):
                        try:
                            client = openai.OpenAI(api_key=OPENAI_API_KEY)
                            prompt = f"""
                            ë‹¹ì‹ ì€ ì„ì› ë¦¬ë”ì‹­ ì½”ì¹˜ì…ë‹ˆë‹¤. 3ë…„ì¹˜ ì£¼ê´€ì‹ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìš”ì•½í•´ì£¼ì„¸ìš”.
                            
                            1. **í•µì‹¬ ê°•ì  (Top 3)**
                            2. **ì£¼ìš” ë³´ì™„ì  ë° Risk**
                            3. **ì—°ë„ë³„ ë³€í™” íë¦„**
                            
                            [ë°ì´í„°]
                            {comments_text}
                            """
                            res = client.chat.completions.create(
                                model="gpt-4o",
                                messages=[{"role": "user", "content": prompt}]
                            )
                            analysis = res.choices[0].message.content
                            st.success("ë¶„ì„ ì™„ë£Œ")
                            st.markdown(analysis)
                            st.session_state['qualitative_analysis'] = analysis
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜: {e}")
            
            with st.expander("ì›ë³¸ ë°ì´í„° ë³´ê¸°"):
                st.text(comments_text)

    # [TAB 3] AI ì½”ì¹­
    with tab3:
        st.subheader("ğŸ’¬ AI ë¦¬ë”ì‹­ ì½”ì¹­")
        
        chat_container = st.container()
        
        if "messages" not in st.session_state:
            st.session_state.messages = []
            
            welcome = f"{selected_leader_name} ì„ì›ë‹˜, ë°˜ê°‘ìŠµë‹ˆë‹¤. 3ë…„ì¹˜ ë¦¬ë”ì‹­ ë°ì´í„° ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.\n\n"
            welcome += f"ìµœê·¼({latest_year}) êµ¬ì„±ì› í‰ê°€ ê¸°ì¤€ ì¢…í•© ì ìˆ˜ëŠ” **{curr_score:.2f}ì **ì…ë‹ˆë‹¤. "
            if delta_total > 0: welcome += "ì „ë…„ ëŒ€ë¹„ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤. ğŸ“ˆ\n\n"
            elif delta_total < 0: welcome += "ì „ë…„ ëŒ€ë¹„ ë‹¤ì†Œ í•˜ë½í–ˆìŠµë‹ˆë‹¤. ğŸ“‰\n\n"
            
            welcome += "í˜„ì¬ ê°€ì¥ ê³ ë¯¼ë˜ì‹œëŠ” ë¦¬ë”ì‹­ ì´ìŠˆëŠ” ë¬´ì—‡ì¸ê°€ìš”? í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì‹œë©´ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.\n\n"
            
            welcome += """---
            ğŸ’¡ **ì¶”ê°€ë¡œ ë…¼ì˜í•  ìˆ˜ ìˆëŠ” ì£¼ì œë“¤** (ì•„ë˜ ë‚´ìš©ì„ ë³µì‚¬í•´ì„œ ì§ˆë¬¸í•˜ì‹œë©´ ì‹¬ë„ ìˆê²Œ ë‹¤ë¤„ë“œë¦½ë‹ˆë‹¤)
            * ğŸ“š **ì´ë¡  í•™ìŠµ:** í˜„ì¬ ë‚˜ì˜ ì•½ì ê³¼ ê´€ë ¨ëœ ìµœì‹  ë¦¬ë”ì‹­ ì´ë¡ ì´ë‚˜ ì•„í‹°í´ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.
            * ğŸ¬ **ì˜ìƒ ì¶”ì²œ:** ë¦¬ë”ì‹­ ê°œë°œì— ë„ì›€ì´ ë  ë§Œí•œ TED ê°•ì—°ì´ë‚˜ êµìœ¡ ì˜ìƒì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.
            * ğŸ—“ï¸ **W/S ì œì•ˆ:** íŒ€ì›ë“¤ê³¼ ì†Œí†µì„ ê°•í™”í•˜ê¸° ìœ„í•œ ì›Œí¬ìˆ ì•„ì  ë‹¤ë¥¼ ì œì•ˆí•´ ì£¼ì„¸ìš”.
            (ì§ˆë¬¸ ì¤‘ ì›í•˜ëŠ” ë‚´ìš©ì„ ë³µì‚¬ ë¶™ì—¬ë„£ê¸° í•˜ì‹œë©´ ì¶”ê°€ë¡œ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤)
            """
            
            st.session_state.messages.append({"role": "assistant", "content": welcome})
            
        with chat_container:
            for msg in st.session_state.messages:
                with st.chat_message(msg["role"]):
                    st.write(msg["content"])
        
        if prompt := st.chat_input("ì§ˆë¬¸ ì…ë ¥..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with chat_container:
                with st.chat_message("user"):
                    st.write(prompt)
            
            if OPENAI_API_KEY:
                try:
                    client = openai.OpenAI(api_key=OPENAI_API_KEY)
                    qual_context = st.session_state.get('qualitative_analysis', "")
                    
                    sys_msg = f"""
                    ë‹¹ì‹ ì€ ëŒ€ê¸°ì—… ì„ì› ì „ìš© ì „ë¬¸ ë¦¬ë”ì‹­ ì½”ì¹˜(Executive Coach)ì…ë‹ˆë‹¤.
                    ëŒ€ìƒ: {selected_leader_name} ì„ì›
                    
                    [ì •ëŸ‰ ë°ì´í„°]
                    - 3ë…„ì¹˜ ì ìˆ˜ ì¶”ì´: {avg_scores}
                    - ìµœì‹  ê°•ì : {top_comp}, ì•½ì : {bot_comp}
                    
                    [ì •ì„± í”¼ë“œë°± ìš”ì•½]
                    {qual_context}
                    
                    [ëŒ€í™” ë° ì‘ë‹µ ê°€ì´ë“œ]
                    1. **ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜:** ì‹¤ì œ ì½”ì¹­ ì„¸ì…˜ì²˜ëŸ¼ ì •ì¤‘í•˜ê³  ê¹Šì´ ìˆëŠ” í†µì°°ì„ ì œê³µí•˜ì„¸ìš”. ë‹¨ìˆœí•œ ë‹µë³€ë³´ë‹¤ëŠ” ì‚¬ìš©ìì˜ ìƒê°ì„ í™•ì¥ì‹œí‚¤ëŠ” ì§ˆë¬¸ì„ ë˜ì§€ì„¸ìš”.
                    2. **ì¶”ê°€ ì œì•ˆ (ì˜µì…˜):** ì‚¬ìš©ìê°€ íŠ¹ì • ì•½ì ì´ë‚˜ ê°œë°œ í¬ì¸íŠ¸ì— ëŒ€í•´ ê³ ë¯¼í•  ë•Œë§Œ, ê´€ë ¨ëœ ì´ë¡  í•™ìŠµ, ì˜ìƒ ì¶”ì²œ, ì›Œí¬ìˆ ì¼ì • ë“±ì„ ì œì•ˆí•˜ì„¸ìš”. (ë§¤ë²ˆ í•  í•„ìš” ì—†ìŒ)
                    3. **Next Step ì§ˆë¬¸ (í•„ìˆ˜):** ë‹µë³€ì˜ ë§ˆì§€ë§‰ì—ëŠ” í•­ìƒ ì½”ì¹­ ê¸°ë²•(GROW, ì§ˆë¬¸ë²• ë“±)ì„ í™œìš©í•˜ì—¬ ìƒí™©ì— ë§ëŠ” ì‹¬í™” ì§ˆë¬¸ì„ ë˜ì§€ì„¸ìš”.
                       - ë¬¸êµ¬ ì˜ˆì‹œ: (í•´ë‹¹ ì§ˆë¬¸ì— ë‹µì„ í•´ì£¼ì‹œë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ì–´ë‚˜ê°€ ë³´ê² ìŠµë‹ˆë‹¤)
                       - ì£¼ì˜: êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì½”ì¹­ ëª¨ë¸ì„ ì¼ëŠ”ì§€ëŠ” ë°íˆì§€ ë§ˆì„¸ìš”.
                    """
                    
                    msgs = [{"role": "system", "content": sys_msg}] + st.session_state.messages
                    
                    with chat_container:
                        with st.chat_message("assistant"):
                            stream = client.chat.completions.create(model="gpt-4o", messages=msgs, stream=True)
                            res = st.write_stream(stream)
                    st.session_state.messages.append({"role": "assistant", "content": res})
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: {e}")
            else:
                st.warning("API Key ë¯¸ì„¤ì •")
